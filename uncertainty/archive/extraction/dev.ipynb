{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerativeModel\n",
    "import vertexai\n",
    "\n",
    "import extraction_prompts as prompts\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.display import Markdown \n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sharp-airway-408502\"\n",
    "LOCATION = \"us-central1\"\n",
    "GUEST = \"Leopold Aschenbrenner\"\n",
    "HOST = \"Dwarkesh Patel\"\n",
    "DATE = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "AIR_DATE = \"2024-06-04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "model = GenerativeModel(model_name=\"gemini-1.5-flash-001\")\n",
    "\n",
    "with open(\"test.txt\", \"r\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = prompts.system_message.replace(\"<date>\", DATE).replace(\"<air_date>\", AIR_DATE).replace(\"<guest>\", GUEST).replace(\"<host>\", HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regex pattern\n",
    "pattern = re.compile(r'(\\w+\\s\\w+)\\s(\\d{2}:\\d{2}:\\d{2})\\n([\\s\\S]+?)(?=\\n\\w+\\s\\w+\\s\\d{2}:\\d{2}:\\d{2}|$)')\n",
    "\n",
    "# Extract matches from the content\n",
    "matches = pattern.findall(transcript)\n",
    "\n",
    "# Create a list of dictionaries with speaker, start time, and text\n",
    "transcript_entries = [{'speaker': match[0], 'start_time': match[1], 'text': match[2].strip()} for match in matches]\n",
    "\n",
    "df = pd.DataFrame(transcript_entries)\n",
    "\n",
    "# Identify the second speaker\n",
    "second_speaker = GUEST\n",
    "\n",
    "# Initialize chunks list\n",
    "chunks = []\n",
    "\n",
    "# Loop through the dataframe\n",
    "i = 0\n",
    "while i < len(df):\n",
    "    if df.loc[i, 'speaker'] == second_speaker:\n",
    "        # Capture the preceding beliefs by the first speaker\n",
    "        preceding_beliefs = []\n",
    "        j = i - 1\n",
    "        while j >= 0 and df.loc[j, 'speaker'] != second_speaker:\n",
    "            preceding_beliefs.insert(0, f\"{df.loc[j, 'speaker']}\\n{df.loc[j, 'text']}\")\n",
    "            j -= 1\n",
    "        \n",
    "        # Capture the second speaker's belief\n",
    "        second_speaker_beliefs = []\n",
    "        while i < len(df) and df.loc[i, 'speaker'] == second_speaker:\n",
    "            second_speaker_beliefs.append(f\"{df.loc[i, 'speaker']}\\n{df.loc[i, 'text']}\")\n",
    "            i += 1\n",
    "        \n",
    "        # Capture the subsequent beliefs by the first speaker\n",
    "        following_beliefs = []\n",
    "        while i < len(df) and df.loc[i, 'speaker'] != second_speaker:\n",
    "            following_beliefs.append(f\"{df.loc[i, 'speaker']}\\n{df.loc[i, 'text']}\")\n",
    "            i += 1\n",
    "        \n",
    "        # Combine all beliefs into one chunk\n",
    "        chunk = \"\\n\".join(preceding_beliefs + second_speaker_beliefs + following_beliefs)\n",
    "        chunks.append(chunk)\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from chunks\n",
    "extraction_df = pd.DataFrame(chunks, columns=['chunk'])\n",
    "\n",
    "# Create a column that contains the chunk for the current index as well as the 2 chunks before and after\n",
    "meta_chunks = []\n",
    "\n",
    "for index in range(len(extraction_df)):\n",
    "    if index < 3:\n",
    "        meta_chunk = \"\\n\\n\".join(extraction_df['chunk'].iloc[:5])\n",
    "    elif index >= len(extraction_df) - 3:\n",
    "        meta_chunk = \"\\n\\n\".join(extraction_df['chunk'].iloc[-5:])\n",
    "    else:\n",
    "        meta_chunk = \"\\n\\n\".join(extraction_df['chunk'].iloc[index-2:index+3])\n",
    "    meta_chunks.append(meta_chunk)\n",
    "\n",
    "extraction_df['meta_chunk'] = meta_chunks\n",
    "\n",
    "extraction_df = extraction_df.reset_index().rename(columns={'index': 'chunk_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a retrying function with exponential backoff\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=60))\n",
    "def process_row(row):\n",
    "    prompt = system_message + prompts.belief_extraction.replace(\"<chunk>\", row['chunk']).replace(\"<guest>\", GUEST).replace(\"<host>\", HOST).replace(\"<meta_chunk>\", row['meta_chunk'])\n",
    "    try:\n",
    "        response = model.generate_content(contents=prompt, generation_config={\"response_mime_type\": \"application/json\"})\n",
    "        response_json = json.loads(response.text)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Raise an exception to trigger retry\n",
    "        raise ValueError(\"JSON decoding error, triggering retry\") from e\n",
    "    except ValueError as e:\n",
    "        # Handle specific ValueError related to blocked content\n",
    "        return f\"Error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        # Handle other potential errors\n",
    "        return f\"Unexpected Error: {str(e)}\"\n",
    "\n",
    "# Use ThreadPoolExecutor for multithreading with tqdm progress bar\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    extracted_beliefs = list(tqdm(executor.map(process_chunk, extraction_df.to_dict('records')), total=len(extraction_df)))\n",
    "\n",
    "# Add the extracted beliefs to the DataFrame\n",
    "extraction_df['extracted_beliefs'] = extracted_beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_df = extraction_df.explode('extracted_beliefs')\n",
    "extraction_df = extraction_df.reset_index(drop=True).reset_index().rename(columns={'index': 'belief_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df = pd.json_normalize(extraction_df['extracted_beliefs'])\n",
    "extraction_df = pd.merge(extraction_df, extracted_df, left_on='belief_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a retrying function with exponential backoff\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=60))\n",
    "def process_chunk(row):\n",
    "    prompt = system_message + prompts.verification_evaluation.replace(\"<chunk>\", row['chunk']).replace(\"<belief>\", json.dumps(row['extracted_beliefs'], indent=4)).replace(\"<guest>\", GUEST).replace(\"<host>\", HOST).replace(\"<meta_chunk>\", row['meta_chunk'])\n",
    "    try:\n",
    "        response = model.generate_content(contents=prompt, generation_config={\"response_mime_type\": \"application/json\"})\n",
    "        response_json = json.loads(response.text)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(e)\n",
    "        # Raise an exception to trigger retry\n",
    "        raise ValueError(\"JSON decoding error, triggering retry\") from e\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        # Handle specific ValueError related to blocked content\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # Handle other potential errors\n",
    "        return None\n",
    "\n",
    "temp_df = extraction_df.dropna(subset=['belief']).copy()\n",
    "\n",
    "# Use ThreadPoolExecutor for multithreading with tqdm progress bar\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    verification_list = list(tqdm(executor.map(process_chunk, temp_df.to_dict('records')), total=len(extraction_df)))\n",
    "\n",
    "# Add the extracted beliefs to the DataFrame\n",
    "temp_df['verification_output'] = verification_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_df = pd.json_normalize(temp_df['verification_output']).drop(columns=['belief'])\n",
    "extraction_df = pd.merge(temp_df, verification_df, left_on='belief_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_df = extraction_df[extraction_df['verify'] == True].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=60))\n",
    "def process_row(row):\n",
    "    prompt = (system_message + prompts.hypothesis_generation\n",
    "              .replace(\"<chunk>\", str(row['chunk']))\n",
    "              .replace(\"<meta_chunk>\", row['meta_chunk'])\n",
    "              .replace(\"<belief>\", str(row['belief']))\n",
    "              .replace(\"<context>\", str(row['context']))\n",
    "              .replace(\"<justification>\", str(row['justification']))\n",
    "              .replace(\"<verification_focus>\", str(row['verification_focus']))\n",
    "              .replace(\"<guest>\", GUEST)\n",
    "              .replace(\"<host>\", HOST)\n",
    "              )\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(contents=prompt, generation_config={\"response_mime_type\": \"application/json\"})\n",
    "        response_json = json.loads(response.text)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Raise an exception to trigger retry\n",
    "        raise ValueError(\"JSON decoding error, triggering retry\") from e\n",
    "    except ValueError as e:\n",
    "        # Handle specific ValueError related to blocked content\n",
    "        return f\"Error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        # Handle other potential errors\n",
    "        return f\"Unexpected Error: {str(e)}\"\n",
    "\n",
    "# Assuming research_df is your DataFrame\n",
    "# Use ThreadPoolExecutor for multithreading with tqdm progress bar\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    hypotheses_list = list(tqdm(executor.map(process_row, research_df.to_dict('records')), total=len(research_df)))\n",
    "\n",
    "# Add the extracted beliefs to the DataFrame\n",
    "research_df['hypotheses_list'] = hypotheses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_df = research_df.explode('hypotheses_list')\n",
    "\n",
    "research_df = research_df.reset_index(drop=True).reset_index().rename(columns={'index': 'hypothesis_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_df = pd.json_normalize(research_df['hypotheses_list'])\n",
    "research_df = pd.merge(research_df, hypotheses_df, left_on='hypothesis_id', right_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
